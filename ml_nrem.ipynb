{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electroencephalograpic classification of human non-REM sleep stages \n",
    "- Electroencephalography: EEG\n",
    "- Surface measurement of post-synaptic potentials across millions of neurons\n",
    "- spatial resolution: brain lobes, approximately\n",
    "\n",
    "![Human brain lobar anatomy](img/brain_lobes_wiki.png)\n",
    "\n",
    "EEG cap layout:\n",
    "- Electrode names \n",
    "  - even numbers are over the right hemisphere\n",
    "  - odd numbers are over the left hemisphere,\n",
    "  - the letter 'z' (e.g. Fz, Cz, Pz) indicate an electrode over the central line (nasion to inion)\n",
    "  - the letters **F, T, P, O** indicate the nearest brain lobe, **Fp** denotes fronto-polar, and **C** indicates the region around the central sulcus; the **A** electrodes are attached near the ears and are assumed to record _no_ relevant brain activity\n",
    "\n",
    "- **Knowledge check**:\n",
    "    - the precentral gyrus belongs to the __ lobe, and its function is __\n",
    "    - the postcentral gyrus belongs to the __ lobe, and its function is __\n",
    "![EEG sensor names](img/21_electrodes_of_International_10-20_system_for_EEG.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_nrem import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sample EEG data\n",
    "- Every time you execute the code cell below, a pair or random 10 second EEG segments will be shown.\n",
    "- Below, the frequency spectra (power spectral density) of the two traces is shown as well.\n",
    "- One trace is taken from an EEG epoch that was scored as wakefulness (**W**) by a human scorer; the other trace was scored as (light) non-REM sleep stage **N1**\n",
    "- **TASKS**\n",
    "  - Can you identify which EEG trace is from wakefulness and which one is N1 sleep?\n",
    "    1. During wakefulness, healthy adults show alpha oscillations (8-12 Hz) over posterior brain regions\n",
    "    2. The American Association for Sleep Medicine (AASM) Manual for Scoring Sleep (2007) asks the human scorer to label the EEG epoch as N1 (light sleep) \"_if alpha rhythm is replaced by low amplitude, mixed frequency activity for more than 50% of the epoch_\"\n",
    "  - The rules are applied to 30 second EEG pages. Explain why some of the 10 sec segments are easier to classify than others\n",
    "  - Do all subjects have identical peak alpha frequencies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this code cell several times to inspect random 10 sec EEG snippets\n",
    "fig = show_random_data()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier\n",
    "\n",
    "https://miro.medium.com/v2/resize:fit:640/format:webp/1*i0o8mjFfCn-uD79-F1Cqkw.png\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make spectral features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select frequency bands: True, False\n",
    "delta = not True\n",
    "theta = True\n",
    "alpha = True\n",
    "beta = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, feature_names = make_features(delta, theta, alpha, beta)\n",
    "\n",
    "plt.figure(figsize=(18,9))\n",
    "plt.imshow(X.T, cmap=plt.cm.bwr)\n",
    "ax = plt.gca()\n",
    "bounds = 1+np.where(np.diff(y))[0]\n",
    "for b in bounds:\n",
    "    ax.axvline(b, color='k')\n",
    "plt.title(\"EEG spectral features for classification\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and optimize classifier\n",
    "- We will split the input (features `X`) and output (targets `y`) variables into two data sets\n",
    "  - training data (80%)\n",
    "  - test data (20%) \n",
    "- Discuss why this might be helpful?\n",
    "- Discuss overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp = np.load(\"spectral_features.npz\")\n",
    "#X = tmp['X']\n",
    "#y = tmp['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params = { \n",
    "    'max_features': [5, 15, 25], \n",
    "}\n",
    "# ['sqrt', 3, 10]\n",
    "#'n_estimators': [100, 200, 300],\n",
    "\n",
    "fixed_params = {\n",
    "    'max_depth': 10,   \n",
    "    'n_estimators': 100,\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "tuning = GridSearchCV(\n",
    "    cv = 10,\n",
    "    estimator = RandomForestClassifier(**fixed_params), \n",
    "    n_jobs = -1, \n",
    "    param_grid = test_params, \n",
    "    scoring = 'accuracy',\n",
    ")\n",
    "print(\"Searching for optimal classifier parameters, be patient...\")\n",
    "tuning.fit(X_train, y_train) # this can take some time...\n",
    "print(\"Optimal parameters found: \", tuning.best_params_)\n",
    "print(f\"Best score obtained on training data: {tuning.best_score_:.3f}\")\n",
    "clf_opt = tuning.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is there anything concerning about the optimal classifier parameters found?\n",
    "- How would you address this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the optimized classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = clf_opt.score(X_test, y_test)\n",
    "print(\"Accuracy on test data: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is the score on test data different from the training data?\n",
    "- Compare with other groups, is there a systematic difference? Explain the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "f_clf_opt = f\"./RFC_opt.pkl\"\n",
    "print(f\"Optimized classifier saved as: {f_clf_opt:s}\")\n",
    "with open(f_clf_opt, 'wb') as fp:\n",
    "    pickle.dump(clf_opt, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask the classifier which features were the most important for classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sort = np.argsort(clf_opt.feature_importances_)[::-1]\n",
    "feature_importances_sorted = np.array(clf_opt.feature_importances_)[idx_sort]\n",
    "feature_names_sorted = np.array(feature_names)[idx_sort]\n",
    "feat_max = 20\n",
    "for i, fimp in enumerate(feature_importances_sorted[:feat_max]):\n",
    "    print(f\"{i:d}, {feature_names_sorted[i]:s}: {100*fimp:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = clf_opt.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_predicted)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=sleep_stages)\n",
    "disp.plot()\n",
    "plt.title(f\"Confusion matrix\\nRandom Forest Classification of sleep_stages (spectral features)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Give a verbal explanation of the confusion matrix, what does it tell you?\n",
    "- Why is the term _confusion_ used?\n",
    "- What are common confusions?\n",
    "- Does the Random Forest Classifier find a similar relationship about which sleep stages are _neighbours_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = clf_opt.score(X_test, y_test)\n",
    "y_predicted = clf_opt.predict(X_test)\n",
    "class_report = classification_report(y_test, y_predicted)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Look up the definitions of precision and recall (have you heard of sensitivity and specificity?)\n",
    "- Which sleep stage is the least likely to be confused with another sleep stage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-score cross-validation\n",
    "n_cv = 10\n",
    "\n",
    "print(f\"\\n[+] Cross-validation (N={n_cv:d}) on TRUE labels (wait...)\")\n",
    "folds = StratifiedShuffleSplit(n_splits = n_cv, train_size = 0.8)\n",
    "scores = []\n",
    "for idx_train, idx_test in folds.split(X, y):\n",
    "    X_train, y_train, X_test, y_test = X[idx_train], y[idx_train], X[idx_test], y[idx_test]\n",
    "    #clf_opt.fit(X_train, y_train)\n",
    "    y_pred = clf_opt.predict(X_test) # [:, 1]\n",
    "    f1 = f1_score(y_test, y_pred, average = None, labels = [1])[0]\n",
    "    scores.append(f1)\n",
    "scores_mean = np.mean(scores)\n",
    "scores_std = np.std(scores)   \n",
    "print(f\"F1-scores: mean={scores_mean:.2f}, std={scores_std:.2f}\")\n",
    "\n",
    "print(f\"\\n[+] Cross-validation (N={n_cv:d}) on SHUFFLED labels (wait...)\")\n",
    "y_shuffled = np.random.permutation(y) # test against shuffled labels\n",
    "folds = StratifiedShuffleSplit(n_splits = n_cv, train_size = 0.8)\n",
    "scores_shuffled = []\n",
    "for idx_train, idx_test in folds.split(X, y_shuffled):\n",
    "    X_train, y_train, X_test, y_test = X[idx_train], y_shuffled[idx_train], X[idx_test], y_shuffled[idx_test]\n",
    "    #clf_opt.fit(X_train, y_train)\n",
    "    y_pred = clf_opt.predict(X_test) # [:, 1]\n",
    "    f1 = f1_score(y_test, y_pred, average = None, labels = [1])[0]\n",
    "    scores_shuffled.append(f1)\n",
    "scores_shuffled_mean = np.mean(scores_shuffled)\n",
    "scores_shuffled_std = np.std(scores_shuffled) \n",
    "print((f\"F1-scores: mean={scores_shuffled_mean:.2f}, std={scores_shuffled_std:.2f}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "t, p_mw = mannwhitneyu(scores, scores_shuffled)\n",
    "print(f\"\\n[+] Mann-Whitney U test: p = {p_mw:.4f}\")\n",
    "alpha = 0.05\n",
    "if ((scores_mean > scores_shuffled_mean) and p_mw < alpha):\n",
    "    print(\"Classifier performance IS statistically significant.\")\n",
    "else:\n",
    "    print(\"Classifier performance IS NOT statistically significant.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
